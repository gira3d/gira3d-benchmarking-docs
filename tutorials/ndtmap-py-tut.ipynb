{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c2a340-5b58-4d76-a518-4dd98fe68eed",
   "metadata": {},
   "source": [
    "# (Intensity) NDTMap Python Bindings\n",
    "In addition to the SOGMM work, we also provide python bindings over the widely used Normal Distributions Transform (NDT) mapping work [1]. These python bindings were created for performance comparison with SOGMM. Thus, we made changes to incorporate intensity values in the regular grid. Our fork of the NDTMap repository is included in the `dry` workspace.\n",
    "\n",
    "The setup for input data is the same as in the preceding tutorial.\n",
    "\n",
    "If you use these bindings in your work, please cite the NDTMap paper [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a298a77-0945-4eee-9e8a-f5af2a250329",
   "metadata": {},
   "source": [
    "## Creating the NDTMap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1898c1d-181e-41fb-96c3-4554bc70aa91",
   "metadata": {},
   "source": [
    "Import the NDTMap and LazyGrid class and specify the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d827e6d-53a1-49c2-82b9-ea4e52ac0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from sogmm_py.utils import read_log_trajectory, o3d_to_np, np_to_o3d\n",
    "from sogmm_py.vis_open3d import VisOpen3D\n",
    "\n",
    "from ndt_map import LazyGrid, NDTMap\n",
    "\n",
    "frame = 1763\n",
    "datasetname = 'lounge'\n",
    "\n",
    "pcld_gt = o3d.io.read_point_cloud('./gira3d-tutorial-data/pcd_' +\n",
    "                                  str(datasetname) +\n",
    "                                  '_' + str(frame) +\n",
    "                                  '_decimate_1_0.pcd', format='pcd')\n",
    "pcld_gt_np = o3d_to_np(pcld_gt)\n",
    "\n",
    "traj = read_log_trajectory('./gira3d-tutorial-data/' +\n",
    "                           str(datasetname) + '-traj.log')\n",
    "pcld_pose = traj[frame].pose\n",
    "\n",
    "K = np.eye(3)\n",
    "K[0, 0] = 525.0\n",
    "K[1, 1] = 525.0\n",
    "K[0, 2] = 319.5\n",
    "K[1, 2] = 239.5\n",
    "\n",
    "W = (int)(640)\n",
    "H = (int)(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dd1aa-3c51-43f6-a4d7-b75b063f9966",
   "metadata": {},
   "source": [
    "Specify the resolution for the NDTMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811bba65-37e1-45df-9768-3822f48b6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.02 # let us go with 2cm for this tutorial\n",
    "l = LazyGrid(res)\n",
    "n = NDTMap(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed6d09-e258-412a-9bed-e237f5ba84aa",
   "metadata": {},
   "source": [
    "Load the ground truth point cloud into the NDTMap model and update the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a08828-41e9-4e1d-9412-9cbec7ee7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.load_pointcloud(pcld_gt_np)\n",
    "n.compute_ndt_cells_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e460cb-e7a4-4aaf-bbac-5307f59f0f17",
   "metadata": {},
   "source": [
    "## Inference for Intensity Image\n",
    "For inference, we treat each cell in the NDT as an equally weighted Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d6a9b1-33a1-4a50-bba0-6fcfdb55ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_pcld = n.get_intensity_at_pcld(pcld_gt_np[:, 0:3])\n",
    "\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(recon_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5287d-9a7a-4dd2-94c3-86df4898f100",
   "metadata": {},
   "source": [
    "![Reconstructed Point Cloud](./results/ndtmap-py-tut-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e4743-3ef3-490c-9814-a925b7ec2168",
   "metadata": {},
   "source": [
    "## Dense Sampling for 3D Point Cloud Reconstruction\n",
    "Same as the SOGMM case, this can be performed using the usual Box-Mueller sampling method [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71c91cc-95ea-460e-9eab-3c203af3a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, means, covs = n.get_gaussians()\n",
    "weights /= np.sum(weights)\n",
    "n_comps = np.shape(weights)[0]\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sogmm_py.utils import matrix_to_tensor\n",
    "ndt_gmm = GaussianMixture(n_components=n_comps, covariance_type='full')\n",
    "ndt_gmm.weights_ = weights\n",
    "ndt_gmm.means_ = means\n",
    "ndt_gmm.covariances_ = matrix_to_tensor(covs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07751070-8c3f-4f01-9f2c-dffa8715442f",
   "metadata": {},
   "source": [
    "This GMM can be used for inference as in the SOGMM case. Let us visualize this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d836870d-9f96-4297-b59c-7f313c925188",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_pcld, _ = ndt_gmm.sample(pcld_gt_np.shape[0]) # sample 4D points from the model\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(resampled_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd58dd-e12f-469b-9ef2-2940fe9db156",
   "metadata": {},
   "source": [
    "![Resampled Point Cloud](./results/ndtmap-py-tut-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fbdd0-c6eb-43aa-a04e-3723ee723644",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "Same performance measures are computed as in the SOGMM case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f4cd6e-6762-4555-8ecc-3f2169767b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore 0.987417 precision 0.977499 recall 0.997537 recon. mean 0.002502 recon. std. dev. 0.003552\n",
      "psnr 27.299248 ssim 0.813870\n"
     ]
    }
   ],
   "source": [
    "from sogmm_py.utils import calculate_depth_metrics, calculate_color_metrics\n",
    "fsc, pre, re, rm, rs = calculate_depth_metrics(pcld_gt, np_to_o3d(resampled_pcld))\n",
    "print(\"fscore %f precision %f recall %f recon. mean %f recon. std. dev. %f\" % (fsc, pre, re, rm, rs))\n",
    "\n",
    "from sogmm_py.utils import ImageUtils\n",
    "iu = ImageUtils(K) # image manipulation utility\n",
    "_, gt_g = iu.pcld_wf_to_imgs(pcld_pose, pcld_gt_np) # project gt pcld on camera\n",
    "if np.isnan(gt_g).any():\n",
    "    gt_g = np.nan_to_num(gt_g)\n",
    "_, pr_g = iu.pcld_wf_to_imgs(pcld_pose, recon_pcld) # project recon pcld on camera\n",
    "if np.isnan(pr_g).any():\n",
    "    pr_g = np.nan_to_num(pr_g)\n",
    "psnr, ssim = calculate_color_metrics(gt_g, pr_g) # compare the intensity images\n",
    "print(\"psnr %f ssim %f\" % (psnr, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e4d3df-a000-4117-a72a-445f59dbaa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory 227600 bytes\n"
     ]
    }
   ],
   "source": [
    "# computing memory usage\n",
    "M = ndt_gmm.n_components\n",
    "mem_bytes = 4 * M * (1 + 3 + 6)\n",
    "print('memory %d bytes' % (mem_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1d52e-05ab-41db-9c5d-d1dfab769bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "[1] J. P. Saarinen, H. Andreasson, T. Stoyanov et al., “3D normal distributions transform occupancy maps: An efficient representation for mapping in dynamic environments,” The International Journal of Robotics Research, vol. 32, no. 14, pp. 1627–1644, Dec. 2013\n",
    "[2] C. M. Bishop and N. M. Nasrabadi, Pattern recognition and machine\n",
    "learning. Springer, 2006, vol. 4, no. 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
