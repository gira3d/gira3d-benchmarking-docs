{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa5f651-0d99-48bc-ae9f-5ddb89ba386e",
   "metadata": {},
   "source": [
    "# (Intensity) OctoMap Python Bindings\n",
    "In addition to the SOGMM work, we also provide python bindings over the widely used OctoMap work [1]. These python bindings were created for performance comparison with SOGMM. Thus, we made use of the `ColorOcTree` class from the original codebase. Our fork of the OctoMap repository is included in the `dry` workspace.\n",
    "\n",
    "The setup for input data is the same as in the preceding tutorial.\n",
    "\n",
    "If you use these bindings in your work, please cite the OctoMap paper [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d481a56-cac9-46ee-8b2c-4ebc90cc3179",
   "metadata": {},
   "source": [
    "## Creating the OctoMap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe9be7-decb-493f-b3c3-e45611dc408d",
   "metadata": {},
   "source": [
    "Import the `ColorTree` class from `octomap_py` and specify the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "195d58f5-bc58-4362-b2d2-53066bc32878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from sogmm_py.utils import read_log_trajectory, o3d_to_np, np_to_o3d\n",
    "from sogmm_py.vis_open3d import VisOpen3D\n",
    "\n",
    "from octomap_py import ColorOcTree\n",
    "\n",
    "frame = 1763\n",
    "datasetname = 'lounge'\n",
    "\n",
    "pcld_gt = o3d.io.read_point_cloud('./gira3d-tutorial-data/pcd_' +\n",
    "                                  str(datasetname) +\n",
    "                                  '_' + str(frame) +\n",
    "                                  '_decimate_1_0.pcd', format='pcd')\n",
    "pcld_gt_np = o3d_to_np(pcld_gt)\n",
    "\n",
    "traj = read_log_trajectory('./gira3d-tutorial-data/' +\n",
    "                           str(datasetname) + '-traj.log')\n",
    "pcld_pose = traj[frame].pose\n",
    "\n",
    "K = np.eye(3)\n",
    "K[0, 0] = 525.0\n",
    "K[1, 1] = 525.0\n",
    "K[0, 2] = 319.5\n",
    "K[1, 2] = 239.5\n",
    "\n",
    "W = (int)(640)\n",
    "H = (int)(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445f189-e880-4653-8892-56715e3553ef",
   "metadata": {},
   "source": [
    "Specify the minimum leaf size for `ColorOcTree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05702d13-eda5-4de8-bfb0-81d8ad26e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.02 # let us go with 2cm for this tutorial\n",
    "model = ColorOcTree(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ec6ad-d4f8-4c1a-abee-7d43279fba0b",
   "metadata": {},
   "source": [
    "Load the ground truth point cloud into the OctoMap model and update the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43aa5c17-d449-4920-ae86-342317453846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.insert_color_occ_points(pcld_gt_np)\n",
    "model.update_inner_occupancy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12237849-0cf0-4024-99cf-25415fd887f3",
   "metadata": {},
   "source": [
    "## Inference for Intensity Image\n",
    "OctoMap is not a generative model (in contrast to NDTMap and SOGMM). We directly query the available points in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6890eb9a-8ad8-44c0-ab89-7d5b7fcf2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_pcld = np.zeros(pcld_gt_np.shape)\n",
    "recon_pcld[:, 0:3] = pcld_gt_np[:, 0:3] # we are constructing intensity image on gt 3D points\n",
    "regressed_intensities = model.get_color_at_points(pcld_gt_np[:, 0:3])\n",
    "recon_pcld[:, 3] = np.squeeze(regressed_intensities)\n",
    "\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(recon_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a8cee-b640-47e3-8391-fecfe25ddf70",
   "metadata": {},
   "source": [
    "![Reconstructed Point Cloud](./results/octomap-py-tut-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f892580-2d06-4b97-96eb-5e23f3573cc9",
   "metadata": {},
   "source": [
    "## Dense Sampling for 3D Point Cloud Reconstruction\n",
    "We get the lowest level (i.e. highest fidelity) from `ColorOcTree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf5cb1b-ff0c-4392-990b-a5da2ed80d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_pcld = model.get_color_occ_points()\n",
    "\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(resampled_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546c117-98ca-4f06-8256-4513b48faff3",
   "metadata": {},
   "source": [
    "![Resampled Point Cloud](./results/octomap-py-tut-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d8a9f-4e81-4408-a2c6-d6cd1d6c346b",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "Same performance measures are computed as in the SOGMM case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee9a1b8-54d3-4d83-937f-ce54b772bd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore 0.610435 precision 0.526697 recall 0.725834 recon. mean 0.009577 recon. std. dev. 0.002803\n",
      "psnr 22.993741 ssim 0.759709\n"
     ]
    }
   ],
   "source": [
    "from sogmm_py.utils import calculate_depth_metrics, calculate_color_metrics\n",
    "fsc, pre, re, rm, rs = calculate_depth_metrics(pcld_gt, np_to_o3d(resampled_pcld))\n",
    "print(\"fscore %f precision %f recall %f recon. mean %f recon. std. dev. %f\" % (fsc, pre, re, rm, rs))\n",
    "\n",
    "from sogmm_py.utils import ImageUtils\n",
    "iu = ImageUtils(K) # image manipulation utility\n",
    "_, gt_g = iu.pcld_wf_to_imgs(pcld_pose, pcld_gt_np) # project gt pcld on camera\n",
    "if np.isnan(gt_g).any():\n",
    "    gt_g = np.nan_to_num(gt_g)\n",
    "_, pr_g = iu.pcld_wf_to_imgs(pcld_pose, recon_pcld) # project recon pcld on camera\n",
    "if np.isnan(pr_g).any():\n",
    "    pr_g = np.nan_to_num(pr_g)\n",
    "psnr, ssim = calculate_color_metrics(gt_g, pr_g) # compare the intensity images\n",
    "print(\"psnr %f ssim %f\" % (psnr, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f150f262-bbc7-4fa6-b854-2bb28432bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory 117715 bytes\n"
     ]
    }
   ],
   "source": [
    "# computing memory usage\n",
    "model.write('temp.ot')\n",
    "import os\n",
    "mem_bytes = os.path.getsize('temp.ot')\n",
    "print('memory %d bytes' % (mem_bytes))\n",
    "!rm temp.ot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fede16-21e6-4c58-8180-07bcbe086da7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "[1] A. Hornung, K. M. Wurm, M. Bennewitz et al., “OctoMap: An efficient probabilistic 3D mapping framework based on octrees,” Autonomous Robots, vol. 34, no. 3, pp. 189–206, Apr. 2013"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
